\documentclass{exam}

\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{fancyvrb}
\usepackage{amsmath}
\usepackage{amssymb}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
	backgroundcolor=\color{white},			% choose the background color
	basicstyle=\small\ttfamily,				% the size of the fonts that are used for the code
	breakatwhitespace=false,				% sets if automatic breaks should only happen at whitespace
	breaklines=true,						% sets automatic line breaking
	captionpos=b,							% sets the caption-position to bottom
	columns=fullflexible,
	commentstyle=\color{mygreen},			% comment style
	deletekeywords={...},					% if you want to delete keywords from the given language
	escapeinside={\%*}{*)},					% if you want to add LaTeX within your code
	extendedchars=true,						% lets you use non-ASCII characters
	frame=single,							% adds a frame around the code
	keepspaces=true,						% keeps spaces in text, useful for keeping indentation of code
	keywordstyle=\color{blue},				% keyword style
	language=Octave,						% the language of the code
	morekeywords={*,...},					% if you want to add more keywords to the set
	showspaces=false,						% show spaces everywhere adding particular underscores
	showstringspaces=false,					% underline spaces within strings only
	showtabs=false,							% show tabs within strings adding particular underscores
	stepnumber=1,							% the step between two line-numbers
	stringstyle=\color{mymauve},			% string literal style
	tabsize=2,								% sets default tabsize to 2 spaces
	title=\lstname							% show the filename of files included with \lstinputlisting
}

\newcommand{\octavescript}[2]{
	\lstinputlisting[caption=#2]{#1}
}

\newcommand{\MNLab}{Laborator\ \#7}
\newcommand{\MNLabTitle}{Calculul valorilor proprii şi vectorilor proprii prin metodele puterii. Metoda Householder}
\newcommand{\MNLabTitleHeader}{Valori și vectori proprii}
\newcommand{\MNAuthor}{Andrei STAN, Dumitru-Clementin Cercel, Alexandru Țifrea}

\renewcommand{\contentsname}{Cuprins}
\renewcommand{\figurename}{Figura}
\renewcommand{\refname}{Referințe}
\renewcommand{\tablename}{Tabelul}

\setlength{\parskip}{0.5\baselineskip}

\graphicspath{{./img/}}

\title{
\textmd{\textbf{\MNLabTitle}}
\author{}
\date{}
}

\pagestyle{headandfoot}

\header{Metode Numerice}
{\MNLabTitleHeader}
{2025}
\footer{Facultatea de Automatică și Calculatoare}{}{Pagina \thepage\ din \numpages}

\begin{document}

\begin{coverpages}
	\maketitle
	\thispagestyle{empty}
	\tableofcontents
\end{coverpages}

\section{Obiective laborator}

În urma parcurgerii acestui laborator, studentul va fi capabil să:

\begin{itemize}
	\item utilizeze metoda puterii directe şi metoda puterii inverse pentru a
	      determina valorile şi vectorii proprii ale unei matrice;
	\item aplice metoda deflației pentru a determina valorile şi vectorii
	      proprii ale unei matrice;
	\item aplice proprietățile valorilor şi vectorilor proprii în rezolvarea
	      unor probleme.
\end{itemize}

\section{Noțiuni teoretice}

Vom începe prin a prezenta conceptul de valoare proprie și vector propriu pentru
o matrice pătrată
$A \in \mathbb{C}^{n\times n}$. Se numește \emph{valoare proprie} a lui $A$
orice număr complex
$\lambda \in \mathbb{C}$ pentru care există un vector nenul
$x \in \mathbb{C}^{n}$ (\emph{vector propriu}), astfel încât
\begin{equation*}
	A x = \lambda x
\end{equation*}

Mulțimea tuturor valorilor proprii ale matricei $A$ se numește \textit{spectrul}
matricei și se notează cu
\begin{equation*}
	\lambda(A) = \{ \lambda_1, \lambda_2, \ldots, \lambda_n\}.
\end{equation*}

Două proprietăți importante ale valorilor proprii ale unei matrice $A\in\mathbb{C}^{n\times n}$ sunt:
\begin{itemize}
	\item $\sum_{i=1}^n \lambda_{i} = \mathrm{tr}(A)$, adică suma
	      valorilor proprii este egală cu urma (suma diagonală) a matricei.
	\item $\prod_{i=1}^n \lambda_{i} = \det(A)$, adică produsul valorilor
	      proprii este determinantul matricei.
\end{itemize}

Pentru a determina practic valorile proprii, se consideră polinomul caracteristic
\(\ p(\lambda) = \det(\lambda I_n - A)\),
iar valorile proprii sunt rădăcinile acestui polinom. Deși acest aspect este
esențial din punct de vedere teoretic, în practică se apelează la Metode
numerice iterative pentru a deterimna valorile și vectorii proprii.

\subsection{Matrice asemenea}

Două matrici $A, B \in \mathbb{C}^{n \times n}$ se numesc \textit{asemenea} dacă
există o matrice nesingulară $T$ astfel încât
\begin{equation*}
	B = T^{-1} A T
\end{equation*}

Ideea de asemănare are la bază simplificarea operațiilor. De exemplu, dacă vrem
să rotim un vector din $\mathbb{R}^2$ în jurul altui vector, putem ca întâi să
schimbăm baza astfel încât vectorul de rotație să devină un vector
standard (de exemplu, să-l aducem pe axa $x$), să aplicăm rotația și apoi să
schimbăm baza înapoi.

Două matrice asemenea au același spectru.

\textbf{Demonstrație.} Fie $A, B \in \mathbb{C}^{n \times n}$ asemenea, adică
$B = T^{-1} A T$. Fie $\lambda \in \mathbb{C}$ o valoare proprie a lui $B$.
\begin{align*}
	B x          & = \lambda x                        \\
	T^{-1} A T y & = \lambda x                        \\
	A (T y)      & = \lambda (T y) \quad \blacksquare \\
\end{align*}

\subsection{Forma Jordan a unei matrice}

Forma Jordan a unei matrice este o formă canonică care permite simplificarea
analizei matricelor, în special în ceea ce privește valorile și vectorii proprii.
O matrice $A$ complexă este mereu similară unei matrice bloc-diagonale de forma:
\begin{equation*}
	J = \begin{bmatrix}
		J_1    & 0      & \cdots & 0      \\
		0      & J_2    & \cdots & 0      \\
		\vdots & \vdots & \ddots & \vdots \\
		0      & 0      & \cdots & J_k
	\end{bmatrix}
\end{equation*}

Fiecare bloc se numește \textit{bloc Jordan} și are forma:
\begin{equation*}
	J_i = \begin{bmatrix}
		\lambda_i & 1         & 0      & \cdots    & 0         \\
		0         & \lambda_i & 1      & \cdots    & 0         \\
		\vdots    & \vdots    & \ddots & \ddots    & \vdots    \\
		0         & 0         & \cdots & \lambda_i & 1         \\
		0         & 0         & \cdots & 0         & \lambda_i
	\end{bmatrix}
\end{equation*}

\subsection{Determinarea vectorilor şi valorilor proprii}

În continuare, vom descrie câteva metode numerice utilizate pentru a determina
valorile şi vectorii proprii ai unei matrice.

\subsubsection{Metoda puterii directe}

Fie matricea $A \in \mathbb{R}^{n\times n}$, cu spectrul
$\lambda(A) = \{\lambda_1, \lambda_2, \dots, \lambda_n\}$ și vectori proprii
normalizați $x_1, x_2, \dots, x_n$. Fie următoarea presupunere:
\begin{equation*}
	|\lambda_1| > |\lambda_2| \geq \dots \geq |\lambda_n|
\end{equation*}

Pentru un vector inițial $y^{(0)} \in \mathbb{R}^{n}$, care are componentă
nenulă pe direcția lui $x_1$, metoda puterii directe construiește șirul
\begin{equation*}
	y^{(k)} = \frac{A y^{(k-1)}}{\|A y^{(k-1)}\|}
\end{equation*}

Șirul $y^{(k)}$ converge către vectorul propriu $x_1$.

\textbf{Demonstrație.} Fie $P^{-1} A P = J$, unde $J$ este matricea Jordan
corespunzătoare lui $A$. Fie $y^{(0)} = \alpha_1 p_1 + \alpha_2 p_2 + \dots + \alpha_n p_n$, unde
$\alpha_1 \neq 0$ și $p_i$ sunt coloanele matricei $P$.
\begin{align*}
	y^{(k)} & = \frac{A y^{(k-1)}}{\|A y^{(k-1)}\|} = \frac{A^k y^{(0)}}{\|A^k y^{(0)}\|}      \\
	        & = \frac{P^{-1} J^k P \sum_i \alpha_i p_i }{\|P^{-1} J^k P \sum_i \alpha_i p_i\|} \\
	        & = \frac{P^{-1} J^k \sum_i \alpha_i e_i}{\|P^{-1} J^k \sum_i \alpha_i e_i\|}      \\
\end{align*}

Din expresia de mai sus, se dă factor comun forțat pe $\lambda_1$ și la numitor
dar și la numărător și trecând la limita $k \to \infty$, ajungem la $y^{(k)} \to v_1$.
Mult mai simplu, dacă $A$ este diagonalizabilă, și $b^{(0)}$ este o combinație
liniară a vectorilor proprii, atunci:
\begin{align*}
	b^{(k)} & = A^k b^{(0)} = A^k \sum_{i=1}^n \alpha_i v_i                                                               \\
	        & = \sum_{i=1}^n \alpha_i A^k v_i = \sum_{i=1}^n \alpha_i \lambda_i^k v_i                                     \\
	        & = \alpha_1 \lambda_1^k ( v_1 +  \sum_{i=2}^n \frac{\alpha_i}{\alpha_1} \frac{\lambda_i^k}{\lambda_1^k} v_i) \\
	b^{(k)} & \to \alpha_1 \lambda_1^k v_1 \quad \blacksquare                                                             \\
\end{align*}

Rata de convergență este dată de $\frac{|\lambda_2|}{|\lambda_1|}$, iar
convergența este rapidă dacă $|\lambda_2| \ll |\lambda_1|$.

\subsubsection{Metoda puterii inverse}

Metoda puterii inverse aplică ideea puterii directe la matricea
$B = A^{-1}$. Valorile proprii ale lui $B$ sunt inversul valorilor proprii ale lui
$A$, deci cea mai mică valoare proprie a lui $A$ corespunde celei mai mari
valori proprii ale matricei $B$. În plus, se poate introduce o deplasare $\mu$,
astfel încât $B = (A - \mu I)^{-1}$. Dacă $\mu$ se află în apropierea uneia
dintre valorile proprii ale lui $A$, atunci iterația va converge către vectorul
propriu asociat lui $\lambda_j$, cu $|\lambda_j - \mu|$ minim.

\textbf{Iterarea câtului Rayleigh.} O versiune mult mai eficientă a metodei
puterii inverse o constituie \textit{iterarea câtului Rayleigh} (sau metoda
puterii inverse cu deplasare variabilă). Aceasta se aplică matricelor hermitice
(simetrice). Pentru o aproximație curentă $x^{(k)}$
a vectorului propriu, se calculează valoarea:
\begin{equation*}
	\rho^{(k)} = \frac{x^{(k) T} A x^{(k)}}{x^{(k) T} x^{(k)}}.
\end{equation*}

Această mărime, numită \textit{cât Rayleigh}, reprezintă o estimare a valorii
proprii asociate lui $x^{(k)}$. Apoi, în pasul următor, se folosește
$\mu = \rho^{(k)}$ drept noua deplasare. Cu alte cuvinte, la fiecare iterație:
\begin{align*}
	y^{(k)}                    & = (A - \rho^{(k)} I)^{-1} x^{(k)} \\
	(A - \rho^{(k)} I) y^{(k)} & = x^{(k)}                         \\
	x^{(k+1)}                  & = \frac{y^{(k)}}{\|y^{(k)}\|}     \\
\end{align*}

Repetând acest procedeu, vectorul și valoarea proprie estimate converg rapid
spre vectorul și valoarea reală asociate lui $\lambda_j$. Această strategie este
extrem de utilă atunci când avem deja un indiciu despre poziția unei valori
proprii, întrucât viteza de convergență devine foarte mare după ce $\rho^{(k)}$
se apropie suficient de $\lambda_j$. În practică, iterarea câtului Rayleigh se
folosește pe scară largă în algoritmi de diagonalizare numerică și este adesea
componenta centrală în metode avansate de calculul valorilor proprii.

\subsection{Deflația}

\textit{Deflația} ne permite ca după ce s-a găsit o valoare proprie și un vector
propriu asociat, să se “reducă” problema la o submatrice pentru determinarea
celorlalte valori proprii. O abordare simplă este \textit{deflația Wielandt}:

\begin{itemize}
	\item Se consideră că am aflat valoarea proprie dominantă $\lambda_1$ și
	      vectorul propriu asociat $x_1$ (de pildă, prin metoda puterii directe).
	\item Se construiește matricea
	      \begin{equation*}
		      B = (I_n - x_1 y^T) A
	      \end{equation*}
	      unde $y \in \mathbb{R}^n$ se alege astfel încât $y^T x_1 = 1$. Se
	      poate arăta că $B$ “blochează” componenta pe direcția $x_1$ și are
	      valorile proprii $\{0, \lambda_2, \lambda_3, \dots,\lambda_n\}$.
	\item Apoi se elimină prima linie și prima coloană (corespunzătoare valorii
	      proprii 0), obținându-se o submatrice care își păstrează celelalte valori
	      proprii $\lambda_2,\ldots,\lambda_n$. Peste această submatrice, se aplică
	      din nou o metodă (de exemplu, puterea directă) pentru a găsi următoarea
	      valoare proprie.
\end{itemize}

\subsection{Algoritmul PageRank}

Matricea Google este un exemplu faimos de matrice stocastică, folosită în
\textit{algoritmul PageRank}. Ideea de bază este că fiecare pagină web este un
nod, iar legăturile (link-urile) către alte pagini definesc o probabilitate de
\textit{tranziție} de la o pagină la alta. Pentru a rezolva probleme de tip
“pagină izolată” sau sub-componente care nu influențează semnificativ restul
rețelei, se folosesc tehnici de \textit{deflație}, prin care se separă anumite
sub-blocuri ale matricei și se rezolvă problema pe blocuri mai mici.

\begin{itemize}
	\item \textbf{Cum se construiește Matricea Google?} Se consideră că avem $n$
	      pagini web, notate $P_1, P_2, \ldots, P_n$. Dacă pagina $P_i$ are link-uri
	      către paginile $P_j$, atunci probabilitatea de a sări din $P_i$ în $P_j$
	      (prin navigare directă) va fi reprezentată ca un element nenul în matricea
	      noastră. Pentru a asigura că matricea este stocastică
	      (fiecare coloană însumează 1), se normalizează după numărul de link-uri
	      ieșire.

	\item \textbf{Exemplu concret cu $N=4$ pagini.} Considerăm 4 pagini web:
	      $P_1, P_2, P_3, P_4$ și următoarea structură de link-uri:
	      \begin{equation*}
		      P_1 \to \{P_2, P_3\}, \quad
		      P_2 \to \{P_3\}, \quad
		      P_3 \to \{P_1, P_4\}, \quad
		      P_4 \to \{P_2\}.
	      \end{equation*}
	      Matricea de \emph{adiacență} (prin linii) ar putea arăta astfel:
	      \begin{equation*}
		      A = \begin{bmatrix}
			      0 & 1 & 1 & 0 \\
			      0 & 0 & 1 & 0 \\
			      1 & 0 & 0 & 1 \\
			      0 & 1 & 0 & 0
		      \end{bmatrix}.
	      \end{equation*}
	      Pentru a obține \emph{matricea de stocastică} $M$, fiecare
	      coloană se normalizează la 1.
	      \begin{equation*}
		      M = \begin{bmatrix}
			      0 & 1/2 & 1/2 & 0 \\
			      0 & 0   & 1/2 & 0 \\
			      1 & 0   & 0   & 1 \\
			      0 & 1/2 & 0   & 0
		      \end{bmatrix}.
	      \end{equation*}

	\item \textbf{Calculul PageRank.} PageRank-ul este o distribuție de
	      probabilitate care indică importanța fiecărei pagini web. PageRank-ul
	      rămâne neschimbat indiferent de ce face utilizatorul, deci satisface
	      ecuația:
	      \begin{equation*}
		      M R = R
	      \end{equation*}
	      Totuși, există șansa ca utilizatorul să nu continue click-urile. Fie
	      $d$ probabilitatea de a continua să navigheze și $1-d$ probabilitatea
	      de a sări la o pagină aleatorie. Astfel, definim matricea Google:
	      \begin{equation*}
		      G = d M + \frac{(1-d)}{N} ONES(N)
	      \end{equation*}
	      PageRank-ul va fi vectorul propriu asociat lui $\lambda=1$ al matricei
	      Google $G$. Cum $\lambda=1$ este și valoare proprie dominantă, se
	      poate aplica metoda puterii.

	\item \textbf{Deflația în PageRank.} Dacă anumite pagini sunt “izolate” sau
	      formează sub-componente, se pot crea blocuri separate pentru care vectorul
	      propriu asociat lui $\lambda=1$ se calculează ușor, după care aceste blocuri
	      pot fi \textit{deflate} pentru a reduce dimensiunea problemei și, implicit,
	      efortul de calcul.
\end{itemize}


% \subsubsection{Metoda Householder}

% Spre deosebire de metodele puterii (care furnizează aproximări ale valorilor și vectorilor proprii), metoda Householder urmărește explicit construirea, prin transformări ortogonale (sau unitare), a unei forme Schur pentru matricea inițială. Această abordare se poate organiza sub forma \emph{algoritmului QR}, care conține două etape:

% \begin{enumerate}
% 	\item \textbf{Etapa directă}, de reducere a matricei date la forma Hessenberg superior prin transformări ortogonale de asemănare.
% 	\item \textbf{Etapa iterativă}, de construcţie recurentă a unui şir de matrici convergent către forma Schur reală. Această etapă folosește ideea factorizării $QR$ a matricei, la care se adaugă eventual \emph{deplasări} (shift-uri) pentru a accelera convergența.
% \end{enumerate}

% Există mai multe variante ale algoritmului QR (cu deplasare simplă, deplasare dublă etc.), însă ideea principală este aceeași: se aplică în mod repetat factorizări și transformări ortogonale, iar în final se ajunge la o matrice aproape triunghiulară, din care citim valorile proprii (pe diagonală sau în blocuri de dimensiune \(2\times 2\)).

\section{Probleme}

\begin{questions}

	\question Fie matricea tridiagonală:

	\[
		A = \begin{bmatrix}
			a_1    & c_1    & \dots   &         &         \\
			b_2    & a_2    & c_2     & \dots   &         \\
			\vdots & \vdots & \ddots  & \ddots  &         \\
			       &        & b_{n-1} & a_{n-1} & c_{n-1} \\
			       &        &         & b_n     & a_n
		\end{bmatrix}.
	\]

	Se construieşte şirul de polinoame:

	\[
		p_0(\lambda) = 1,\quad
		p_1(\lambda) = \lambda - a_1,\quad
		p_n(\lambda) = (\lambda - a_n)\,p_{n-1}(\lambda) - b_n c_{n-1}\,p_{n-2}(\lambda).
	\]

	\begin{enumerate}
		\item Arătaţi că $p_{n}(\lambda)$ este polinomul caracteristic al matricei $A$.
		\item Scrieţi o funcţie OCTAVE care calculează valorile şi vectorii proprii ale matricei $A$.
	\end{enumerate}

	\question

	Să se demonstreze pentru o matrice $A \in \mathbb{R}^{n \times n}$ proprietăţile următoare:

	\begin{enumerate}
		\item $\sigma(A^{-1}) = \left\lbrace \tfrac{1}{\lambda _{1}}, \tfrac{1}{\lambda _{2}}, \ldots, \tfrac{1}{\lambda _{n}}\right\rbrace $;
		\item $\sigma(A - \mu I_{n}) = \left\lbrace \lambda_{i} - \mu \right\rbrace , \forall \mu \in \mathbb{R}$;
		\item $\sigma(A^{k}) = \left\lbrace \lambda_{i}^{k} \right\rbrace , \forall k \in \mathbb{N}$;
		\item $\sigma((A - \mu I_{n})^{- 1}) = \left\lbrace \tfrac{1}{\lambda_{i} - \mu} \right\rbrace , \forall \mu \in \mathbb{R}$.
	\end{enumerate}

	\question
	Calculaţi valorile şi vectorii proprii ai unui reflector Householder.

	\emph{Indicaţie:} $G^T u = e_1G$  - este un reflector. Coloanele lui $G$ sunt vectori proprii.

	\question
	Pentru matricea:
	\[
		A = \begin{bmatrix}
			c & -s \\
			s & c
		\end{bmatrix}
		\in \mathbb{R}^{2 \times 2}, \quad c^2 + s^2 = 1,
	\]
	calculaţi valorile şi vectorii proprii.
\end{questions}
\end{document}
