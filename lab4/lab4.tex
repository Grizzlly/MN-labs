\documentclass{exam}

\usepackage{indentfirst}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
\usepackage{fancyvrb}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
	backgroundcolor=\color{white},		% choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
	basicstyle=\small\ttfamily,		% the size of the fonts that are used for the code
	breakatwhitespace=false,			% sets if automatic breaks should only happen at whitespace
	breaklines=true,					% sets automatic line breaking
	captionpos=b,						% sets the caption-position to bottom
	columns=fullflexible,
	commentstyle=\color{mygreen},		% comment style
	deletekeywords={...},				% if you want to delete keywords from the given language
	escapeinside={\%*}{*)},			% if you want to add LaTeX within your code
	extendedchars=true,				% lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
	frame=single,						% adds a frame around the code
	keepspaces=true,					% keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
	keywordstyle=\color{blue},			% keyword style
	language=Octave,					% the language of the code
	morekeywords={*,...},				% if you want to add more keywords to the set
	%   numbers=left,						% where to put the line-numbers; possible values are (none, left, right)
	%   numbersep=6pt,						% how far the line-numbers are from the code
	%   numberstyle=\tiny\color{mygray},	% the style that is used for the line-numbers
	rulecolor=\color{black},			% if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
	showspaces=false,					% show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
	showstringspaces=false,			% underline spaces within strings only
	showtabs=false,					% show tabs within strings adding particular underscores
	stepnumber=1,						% the step between two line-numbers. If it's 1, each line will be numbered
	stringstyle=\color{mymauve},		% string literal style
	tabsize=2,							% sets default tabsize to 2 spaces
	title=\lstname						% show the filename of files included with \lstinputlisting; also try caption instead of title
}

% Creates a new command to include a perl script, the first parameter is the filename of the script (without .pl), the second parameter is the caption
\newcommand{\octavescript}[2]{
	\lstinputlisting[caption=#2,label=#1]{#1}
}

\newcommand{\MNLab}{Laborator\ \#4}
\newcommand{\MNLabTitle}{Eliminare gaussiană cu pivotare totală și scalare. Algoritmul Thomas pentru rezolvarea sistemului 3-diagonal.}
\newcommand{\MNLabTitleHeader}{Eliminare gaussiană}
\newcommand{\MNAuthor}{Andrei STAN, Florin Pop, Mihaela Andreea-Vasile}

\renewcommand{\contentsname}{Cuprins}
\renewcommand{\figurename}{Figura}
\renewcommand{\refname}{Referințe}

\setlength{\parskip}{0.5\baselineskip}

\graphicspath{{./img/}}

\title{
	\textmd{\textbf{\MNLabTitle}}
	\author{Colaboratori: \MNAuthor}
}

\pagestyle{headandfoot}

\header{Metode Numerice}
{\MNLabTitleHeader, Pagina \thepage\ din \numpages}
{2025}
\footer{Facultatea de Automatică și Calculatoare}{}{Pagina \thepage\ din \numpages}

\begin{document}

\begin{coverpages}

	\maketitle
	\tableofcontents

\end{coverpages}

\section{Obiective laborator}

\par În urma parcurgerii acestui laborator, studentul va fi capabil să:
\begin{itemize}
	\item Transforme o matrice nesingulară într-o matrice superior sau inferior triunghiulară folosind una din metodele prezentate de eliminare gaussiană;
	\item Implementeze algoritmii de eliminare gaussiană prezentați;
	\item Implementeze algoritmul Thomas.
\end{itemize}

\section{Noțiuni teoretice}

\par Eliminarea Gaussiană sau \textit{reducerea coloanelor} este un algoritm
fundamental în algebra liniară. Acesta poate fi folosit pentru rezolvarea
sistemelor liniare, găsirea rang-ului unei matrice, inversarea unei matrice,
sau calcularea determinantului.

\par Algoritmul se bazează pe efectuarea unor operații elementarea pentru a
permuta, scala și combina liniile unei matrici. Gândindu-ne la un sistem de
ecuații liniare, acesta nu se schimbă dacă facem aceste operații. Dacă mai
adăugăm și permutarea coloanelor, atunci soluția sistemului se schimbă doar prin
aceste permutări, ușor de inversat. Obiecivul este să aducem matricea la
\textit{forma eșalon} sau \textit{forma eșalon redusă}.

\par Așadar, opeațiile elementare cu liniile sunt:

\begin{enumerate}
	\item permutarea liniilor;
	\item înmulțirea unei linii cu un scalar nenul;
	\item adunarea unei linii scalate la altă linie.
\end{enumerate}

\subsection{Forma eșalon a unei matrice}

\par Pentru fiecare linie dintr-o matrice, numim prima valoare diferită de zero
\textit{coeficient principal} sau \textit{pivot}. Dacă doi pivoți se găsesc pe
aceeași coloană, putem mereu să facem pe unul dintre ei 0. Ne folosim apoi de
permutari, pentru a aranja liniile în așa fel încât pivotul unei linii să fie
la dreapta pivotului liniei anterioare.

\par De exemplu, matricea de mai jos este în forma eșalon. Observați cum toate
liniile pline de 0 sunt jos.

\begin{equation*}
	\begin{bmatrix}
		0 & 1 & 2 & 3 \\
		0 & 0 & 4 & 5 \\
		0 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0
	\end{bmatrix}
\end{equation*}

\par În plus, putem spune despre o matrice că este în
\textit{forma eșalon redusă} dacă toți pivoții sunt 1 (lucru care se poate
obține prin scalare) și toate celelalte elemente de pe coloana unui pivot sunt 0
(lucru care se poate obține prin adunarea unei linii scalate la altă linie).

\subsection{Matrici elementare}

\par O matrice elementară este o matrice care se obține din matricea identitate
prin efectuarea unei operații elementare cu liniile.

\par \textbf{Matricea de permutare.} Interschimbă liniile $i$ și $j$.

\begin{equation*}
	\begin{split}
		P_{ij} = \begin{bmatrix}
			         1 &        &   &        &   &        &   \\
			           & \ddots &   &        &   &        &   \\
			           &        & 0 &        & 1 &        &   \\
			           &        &   & \ddots &   &        &   \\
			           &        & 1 &        & 0 &        &   \\
			           &        &   &        &   & \ddots &   \\
			           &        &   &        &   &        & 1
		         \end{bmatrix}
	\end{split}
	\quad
	\begin{split}
		 & \text{Construire:}      \\
		 & P = eye(n)              \\
		 & P (i, i) = P (j, j) = 0 \\
		 & P (i, j) = P (j, i) = 1
	\end{split}
\end{equation*}

\par Proprietăți:
\begin{itemize}
	\item $P = P^{-1} = P^T \implies P$ ortogonală
	\item $\det P = -1 \implies \det (PA) = -\det A$
\end{itemize}

\par \textbf{Matricea de scalare.} Înmulțește linia $i$ cu un scalar $\alpha$.

\begin{equation*}
	\begin{split}
		S_{i}(\alpha) = \begin{bmatrix}
			                1 &        &        &        &   \\
			                  & \ddots &        &        &   \\
			                  &        & \alpha &        &   \\
			                  &        &        & \ddots &   \\
			                  &        &        &        & 1
		                \end{bmatrix}
	\end{split}
	\quad
	\begin{split}
		 & \text{Construire:} \\
		 & S = eye(n)         \\
		 & S (i, i) = \alpha
	\end{split}
\end{equation*}

\par Proprietăți:
\begin{itemize}
	\item $D_i(m)^{-1} = D_i (\frac{1}{m})$
	\item $\det S = \alpha \implies \det (SA) = \alpha \det A$
\end{itemize}

\par \textbf{Matricea de adunare.} Adună linia $i$ la linia $j$ înmulțită cu un
scalar $\alpha$.

\begin{equation*}
	\begin{split}
		E_{ij}(\alpha) = \begin{bmatrix}
			                 1 &        &        &        &   &        &   \\
			                   & \ddots &        &        &   &        &   \\
			                   &        & 1      &        &   &        &   \\
			                   &        &        & \ddots &   &        &   \\
			                   &        & \alpha &        & 1 &        &   \\
			                   &        &        &        &   & \ddots &   \\
			                   &        &        &        &   &        & 1
		                 \end{bmatrix}
	\end{split}
	\quad
	\begin{split}
		 & \text{Construire:} \\
		 & E = eye(n)         \\
		 & E (i, j) = \alpha
	\end{split}
\end{equation*}

\par Proprietăți:

\begin{itemize}
	\item $E_{ij}(\alpha)^{-1} = E_{ij}(-\alpha)$
	\item $\det E = 1 \implies \det (EA) = \det A$
\end{itemize}

\subsubsection{Descompunerea LU}

\par Prin aplicare unor astfel de matrice și ajungând la forma eșalon, am ajuns
practic la o matrice superior triunghiulară.

\begin{align*}
	T_nT_{n-1}\ldots T_1 A & = U                                             \\
	A                      & = T_1^{-1}T_2^{-1}\ldots T_n^{-1}U              \\
	A                      & = LU, \quad L = T_1^{-1}T_2^{-1}\ldots T_n^{-1}
\end{align*}

\subsubsection{Calcularea determinantului}

\par După cum am spus la primul laborator, determinantul se calculează prin
formula lui Leibniz în $O(n!)$ operații. Eliminarea Gaussiană are complexitate
$O(n^3)$.

\par Pentru o matrice triunghiulară $U$ avem că $\det U = \prod_{i=1}^{n} u_{ii}$.

\begin{equation*}
	\det A = \frac{\det U}{\prod_{i = 1}^{n} \det T_i}
\end{equation*}

\subsection{Eliminarea gaussiană - G}

\par \textbf{Exemplu.}

\begin{equation*}
	\begin{bmatrix}
		1 & 3  & 1  & 9  \\
		1 & 1  & -1 & 1  \\
		3 & 11 & 8  & 35
	\end{bmatrix} \to
	\begin{bmatrix}
		1 & 3  & 1  & 9  \\
		0 & -2 & -2 & -8 \\
		0 & 2  & 5  & 8
	\end{bmatrix} \to
	\begin{bmatrix}
		1 & 3  & 1  & 9  \\
		0 & -2 & -2 & -8 \\
		0 & 0  & 3  & 0
	\end{bmatrix}
\end{equation*}

\par Agoritmul în MATLAB poate fi gândit astfel:

\begin{enumerate}
	\item Folosesc un $p$ ca să ma plimb pe coloane, până când $p$ este egal
	      cu numărul de linii sau de coloane.
	\item Pivotul meu va fi $a_{pp}$.
	\item Iau restul de elemente de pe coloană folosind un index $i$ și calculez
	      $\mu_{ip} = \frac{a_{ip}}{a_{pp}}$. Acești coeficienți îi pun în
	      matricea $S$, $S(i, p) = -\mu_{ip}$.
	\item Calculez produsul $SA$ și continui cu următoarea coloană.
\end{enumerate}

\newpage
\octavescript{./src/G.m}{}

\par De notat că nu este nevoie să aduce matricea la forma eșalon redusă pentru
a rezolva un sistem, trebuie doar să fie triunghiulară. În codul de mai sus, $A$
este matricea extinsă a sistemului. Ba mai mult, am putea afecta stabilitatea
numerică din cauza efectuării mai multor operații.

\par Alt lucru de observat este că dacă pivotul selectat este 0, atunci
programul "crapă" (womp-womp). Pentru a rezolva acest lucru introducem
conceptul de \textit{pivotare}.

\subsection{Pivotare}

\par Pivotarea constă în folosirea permutărilor și a scalării pentru a alege
cel mai bun pivot. Este clar că eliminearea Gauss poate fi aplicată pe orice
matrice, deci în continuare discuția se va baza pe analiză numerică.

\subsubsection{De ce este pivotarea importantă?}

\par Fie un calculator care folosește aritmetică în virgulă mobilă, cu 3
zecimale, cu trunchiere. Fie următorul sistem:

\begin{equation*}
	\begin{bmatrix}
		0.913 & 0.659 \\
		0.780 & 0.563
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\
		x_2
	\end{bmatrix}
	=
	\begin{bmatrix}
		0.254 \\
		0.217
	\end{bmatrix}
\end{equation*}

\begin{equation*}
	\mu = \frac{0.780}{0.913} = 0.854 \quad \text{(trunchiere)}
\end{equation*}

\par Sistemul devine:

\begin{equation*}
	\begin{bmatrix}
		0.913 & 0.659 \\
		0     & 0.001
	\end{bmatrix}
	\begin{bmatrix}
		x_1 \\
		x_2
	\end{bmatrix}
	=
	\begin{bmatrix}
		0.254 \\
		0.001
	\end{bmatrix}
\end{equation*}

\par Soluțiile sunt $x_2 = 1$ și $x_1 = \frac{0.254 - 0.659}{0.913} = -0.417$.

\par Comparăm soluția găsită, $x_* = \begin{bmatrix} -0.417 \\ 1 \end{bmatrix}$,
cu soluția reală, $x = \begin{bmatrix} -1 \\ 1 \end{bmatrix}$:

\begin{align*}
	||x - x_*||               & = ||\begin{bmatrix} -0.557 \\ 0 \end{bmatrix}|| = 0.557 \\
	||x||                     & = ||\begin{bmatrix} -1 \\ 1 \end{bmatrix}|| = \sqrt{2}  \\
	\frac{||x - x_*||}{||x||} & = \frac{0.557}{\sqrt{2}} = 0.39
\end{align*}

\par Eroarea relativă este de aproape 40\%. Foarte mare! Dacă calculăm reziduul,
am vedea că el este totuși mic, dar pe noi ne interesează soluția. Prezentăm
următoarele strategii:

\begin{itemize}
	\item Pivotare parțială - GPP;
	\item Pivotare parțială cu pivot scalat - GPPS;
	\item Pivotare totală - GPT.
\end{itemize}

\subsubsection{Pivotare parţială - GPP}

\par Pivotarea parțială are loc numai prin permutarea liniilor. La pasul $p$ al
algoritmului se aduce în locul pivotului cel mai mare element din coloană de sub
acesta.

\par Algoritmul în MATLAB se gândește exact la fel, numai că înaintea calculării
coeficienților $\mu_{ip}$ se face permutarea liniilor.

\octavescript{./src/GPP.m}{}

\par Este de observat că această metodă de pivotare încă nu rezolvă eroarea din
sistemul de mai sus, nu se efectuează nicio permutare. Totuși, în general, este
suficientă pentru a face erorile rezonabile. Dacă pivotul ajunge să fie 0,
atunci matricea este singulară.

\subsection{Pivotare parţială cu pivot scalat - GPPS}

\par Această tehnică este similară cu precedenta, doar că definim la început un
factor de scalare pentru fiecare linie $i$, factor de forma:

\begin{equation*}
	s_i = \max_{j=p:n}{\{|a_{ij}|\}} \quad \text{sau} \quad s_i = \sum_{j=p}^{n}{|a_{ij}|}
\end{equation*}

\par Dacă $s_i = 0$ atunci matricea este singulară.

\par Prin această metodă interschimbăm liniile în funcție de elementul cel mai
mare relativ la celelelte elemente de pe linie. Practic, la fiecare pas $p$,
vom căuta întregul $i_p$ astfel încât:

\begin{equation*}
	\frac{|a_{i_p p}|}{s_{i_p}} = \max_{i=p:n}{\frac{|a_{i p}|}{s_i}}
\end{equation*}

\par De exemplu, considerând sistemul
$\begin{bmatrix}
		1 & 10000  \\
		1 & 0.0001
	\end{bmatrix}
	\begin{bmatrix}
		x \\
		y
	\end{bmatrix}
	=
	\begin{bmatrix}
		10000 \\
		1
	\end{bmatrix}
$, folosind GPP nu ar trebui sa interschimbăm liniile, dar avem exact aceeași
problemă cu stabilitatea numerică. În consecință, interschimbăm liniile pentru
că 1 este foarte mic relativ la 10000.

\par Algorimtul în MATLAB este similar cu cel de la GPP, dar introducem
calculul factorului de scalare.

\octavescript{./src/GPPS.m}{}

\subsection{Pivotare totală - GPT}

\par Cea mai bună stabilitate numerică se obține atunci când pivotul este cel
mai mare element în modul, din toata submatricea rămasă. Această tehnică se
numește pivotare totală. Totuși, în practică nu se folosește deoarece trebuie
ca la fiecare iterație să parcurgi toată submatricea. Practic, costurile
sunt mai mari decât beneficiile.

\par Pentru că acum trebuie să permutăm și coloanele, trebuie să ținem minte
aceste permutări. Acest lucru se datorează faptului că se schimbă ordinea
necunoscutelor. Pentru aceste permutări, ne folosim tot de o matrice $P$ numai
că o vom aplica la dreapta.

\par Algoritmul în MATLAB este similar cu cel de la GPP, doar că modificăm
căutarea maximului.

\octavescript{./src/GPT.m}{}

\par Pentru că $A$ este matricea extinsă trebuie să avem grijă cu indicii.
Ultima comandă de \verb|display| demonstrează restabilirea ordinii inițiale a
necunoscutelor.

\subsection{Algoritmul Thomas pentru rezolvarea sistemului 3-diagonal}

Un sistem tridiagonal are ecuații de forma:
\begin{equation*}
	a_i x_{i - 1} + b_i x_i + c_i x_{i + 1} = d_i, \quad a_0 = 0, \quad c_n = 0
\end{equation*}

Iar sub forma matriceală:
\begin{equation*}
	\begin{bmatrix}
		{b_1} & {c_1} & {   }  & {   }  & { 0 }     \\
		{a_2} & {b_2} & {c_2}  & {   }  & {   }     \\
		{   } & {a_3} & {b_3}  & \ddots & {   }     \\
		{   } & {   } & \ddots & \ddots & {c_{n-1}} \\
		{ 0 } & {   } & {   }  & {a_n}  & {b_n}     \\
	\end{bmatrix}
	\begin{bmatrix}
		{x_1 } \\
		{x_2 } \\
		{x_3 } \\
		\vdots \\
		{x_n } \\
	\end{bmatrix}
	=
	\begin{bmatrix}
		{d_1 } \\
		{d_2 } \\
		{d_3 } \\
		\vdots \\
		{d_n } \\
	\end{bmatrix}
\end{equation*}

Un astfel de sistem este un caz special al eliminării Gaussiene și poate fi
rezolvat în doar $O(n)$ operații. Astfel de matrici apar în special la calculul
spline-urilor cubice.

Fie primele 2 ecuații ale unui sistem tridiagonal:
\begin{align*}
	 & b_1 x_1 + c_1 x_2           & = d_1 \\
	 & a_2 x_1 + b_2 x_2 + c_2 x_3 & = d_2
\end{align*}

Facem primul pas din eliminarea gaussiană, cu $\mu = \frac{a_2}{b_1}$:
\begin{align*}
	 & b_1 x_1 + c_1 x_2             & = d_1           \\
	 & (b_1 - \mu c_1) x_2 + c_2 x_3 & = d_2 - \mu d_1
\end{align*}

Necunoscuta $x_1$ a fost eliminată, și am rămas cu o ecuație similară cu prima.
Acest procedeu s-ar continua până la final, deci putem defini coeficienții
recursiv (coeficienții primesi ecuații nu se modifică):
\begin{align*}
	\mu & = \frac{a_i}{b_{i - 1}} \\
	b_i & = b_i - \mu c_{i - 1}   \\
	d_i & = d_i - \mu d_{i - 1}
\end{align*}

În final, soluția sistemului o găsim prin substituție înapoi:
\begin{align*}
	x_n & = \frac{d_n}{b_n}                 \\
	x_i & = \frac{d_i - c_i x_{i + 1}}{b_i}
\end{align*}

Algoritmul în MATLAB îl construim folosind 4 vectori corespunzători
coeficienților și termenilor liberi.

\newpage
\octavescript{./src/Thomas.m}{}

Pentru analiza numerică, este suficient să analizăm ecuația:
\begin{equation*}
	b'_i = b_i - \frac{a_i c_{i - 1}}{b_{i - 1}}
\end{equation*}

După cum am observat în laboratoarele trecute, dacă $|b_{i - 1}|$ este foarte mic,
erorile se pot amplifica atunci când îl calculăm pe $\mu$. În consecință, ne-am
dori ca $|b_i| > |c_i|$. Mai mult, ne dorim ca $|b_i| > |a_i|$. O matrice care
satisface aceste condiții se numește \textit{diagonal dominantă}. Această
matrice este caracterizată de faptul ca elementele de pe diagonala principală
sunt mai mari decât suma elementelor de pe linie, mai exact, în cazul nostru:
\begin{equation*}
	|b_i| \geq |a_i| + |c_i|
\end{equation*}

\section{Probleme rezolvate}

\subsection{Problema 1}

Fie sistemul de ecuații:
$\displaystyle \begin{cases}
		5.2 \cdot x_1 + 7.1 \cdot x_2 = 19.8 \\
		2.4 \cdot x_1 + 3.2\cdot x_2 = 4.1
	\end{cases}$ Rezolva\c{t}i sistemul folosind eliminare gaussian\u{a} cu pivotare par\c{t}ial\u{a}.

\subsection{Problema 5}
Să se scrie un program OCTAVE pentru a implementa algoritmul Thomas de rezolvare a unui sistem 3-diagonal.

\textit{Soluţie:}

\octavescript{./src/Thomas.m}{}


\begin{center}
	\begin{tabular}{| l | l |}
		\hline
		\\
		\textbf{Date de intrare:} \\\\
		$a = $
		$\begin{bmatrix}
				 2 \quad
				 9\quad
				 2 \quad
				 3 \quad
				 6
			 \end{bmatrix}$,

		$b = $
		$\begin{bmatrix}
				 12 \quad
				 15\quad
				 2 \quad
				 9 \quad
				 1 \quad
				 0
			 \end{bmatrix}$,

		$c = $
		$\begin{bmatrix}
				 10 \quad
				 3\quad
				 9 \quad
				 1 \quad
				 4
			 \end{bmatrix}$,

		$d = $
		$\begin{bmatrix}
				 1 \quad
				 5\quad
				 9 \quad
				 11 \quad
				 13 \quad
				 7
			 \end{bmatrix}$

		\\ \\
		\hline
		\\
		\textbf{Date de ieşire:}  \\ \\
		$ x = $
		$\begin{bmatrix}
				 0.160494 \quad
				 -0.092593 \quad
				 2.022634  \quad
				 0.643118  \quad
				 1.166667 \quad
				 2.475995
			 \end{bmatrix}
		$
		\\
		\hline
	\end{tabular}
\end{center}

\section{Probleme}

\begin{questions}
	\boxedpoints
	\pointsinmargin

	%----------------------------------------------------------------------------------------
	%	PROBLEM 3
	%----------------------------------------------------------------------------------------
	\question Construi\c{t}i o variant\u{a} modificat\u{a} pentru algoritmul lui Thomas care s\u{a} lucreze cu matricea:
	\[
		A = \begin{bmatrix}
			{b_1} & { 0 }  & {c_1}      & {   }      & {   }     & {   }     & { 0 }     \\
			{ 0 } & {b_2}  & { 0 }      & {c_2}      & {   }     & {   }     & {   }     \\
			{a_3} & { 0 }  & {b_3}      & { 0 }      & {c_3}     & {   }     & {   }     \\
			{   } & \ddots & \ddots     & \ddots     & \ddots    & \ddots    & {   }     \\
			{   } & {   }  & { a_{n-2}} & { 0 }      & {b_{n-2}} & { 0 }     & {c_{n-2}} \\
			{   } & {   }  & {   }      & { a_{n-1}} & { 0 }     & {b_{n-1}} & { 0 }     \\
			{ 0 } & {   }  & {   }      & {   }      & {a_n}     & { 0 }     & {b_n}     \\
		\end{bmatrix}
	\]

	\question Fie sistemul de ecua\c{t}ii:
	\begin{equation*}
		\begin{cases}
			1.5 \cdot x_1 - 2.1 \cdot x_2 = 8.3 \\
			-7.6 \cdot x_1 + 3.11 \cdot x_2 = 6.7
		\end{cases}
	\end{equation*}
	Rezolvați sistemul folosind eliminare GPP, GPPS, GPT.

\end{questions}

\begin{thebibliography}{1}

	\bibitem{AlgLinNegrescu}
	Alexandru Negrescu. Algebra Liniară. O abordare prietenoasă, 2025, 15(2): 502-505. doi: 10.3934/naco.2023025

\end{thebibliography}

\end{document}
